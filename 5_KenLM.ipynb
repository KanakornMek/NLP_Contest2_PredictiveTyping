{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 5) KenLM with Kneser-Ney Smoothing\n",
    "\n",
    "This notebook implements a language model using KenLM, an optimized n-gram library with Modified Kneser-Ney smoothing.\n",
    "\n",
    "**Model Description:**\n",
    "- Uses KenLM library (highly optimized C++ implementation)\n",
    "- Modified Kneser-Ney smoothing (state-of-the-art for n-grams)\n",
    "- Supports 5-gram with proper backoff\n",
    "- Much faster and more memory-efficient than pure Python\n",
    "\n",
    "**Expected Performance:**\n",
    "- 10K data: ~25-30% accuracy\n",
    "- 100K data: ~45-50% accuracy\n",
    "- 1M data: ~55-60% accuracy\n",
    "- Full (3.8M) data: ~58-65% accuracy\n",
    "\n",
    "**Why KenLM?**\n",
    "- Modified Kneser-Ney > Simple MLE (our previous models)\n",
    "- Handles unseen n-grams much better\n",
    "- Industry standard for n-gram models\n",
    "- Used in Moses MT, speech recognition, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "## 5.1 Setup and Imports\n",
    "\n",
    "First, we need to install KenLM. This requires:\n",
    "1. Installing the KenLM library\n",
    "2. Building the language model with `lmplz`\n",
    "3. Querying the model with Python bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_kenlm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install KenLM\n",
    "# This may take 2-3 minutes\n",
    "!pip install https://github.com/kpu/kenlm/archive/master.zip -q\n",
    "\n",
    "print(\"KenLM installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kenlm\n",
    "import os\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"KenLM version: {kenlm.__version__ if hasattr(kenlm, '__version__') else 'installed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## 5.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('train.src.tok', 'r', encoding='utf-8') as f:\n",
    "    train_lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"Total training sentences: {len(train_lines):,}\")\n",
    "\n",
    "# Load dev set\n",
    "print(\"\\nLoading development set...\")\n",
    "dev_df = pd.read_csv('dev_set.csv')\n",
    "print(f\"Development set size: {len(dev_df):,} predictions\")\n",
    "print(f\"Columns: {list(dev_df.columns)}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample dev set entries:\")\n",
    "print(dev_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_sampling_header",
   "metadata": {},
   "source": [
    "## 5.3 Data Sampling\n",
    "\n",
    "We'll use simple sequential sampling (first N sentences) as decided in EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sizes for experiments\n",
    "DATA_SIZES = {\n",
    "    'debug': 10_000,\n",
    "    'dev': 100_000,\n",
    "    'large': 1_000_000,\n",
    "    'full': 3_803_957\n",
    "}\n",
    "\n",
    "def sample_data(train_lines: List[str], size_key: str = 'debug') -> List[str]:\n",
    "    \"\"\"\n",
    "    Sample training data sequentially (simple, no shuffling).\n",
    "    \n",
    "    Args:\n",
    "        train_lines: Full training corpus\n",
    "        size_key: One of 'debug', 'dev', 'large', 'full'\n",
    "    \n",
    "    Returns:\n",
    "        First N sentences from corpus\n",
    "    \"\"\"\n",
    "    size = DATA_SIZES[size_key]\n",
    "    if size >= len(train_lines):\n",
    "        return train_lines\n",
    "    return train_lines[:size]\n",
    "\n",
    "# Start with debug size (10K) for fast testing\n",
    "# Change to 'dev', 'large', or 'full' later\n",
    "CURRENT_SIZE = 'debug'\n",
    "# CURRENT_SIZE = 'dev'\n",
    "# CURRENT_SIZE = 'large'\n",
    "# CURRENT_SIZE = 'full'\n",
    "\n",
    "train_data = sample_data(train_lines, CURRENT_SIZE)\n",
    "print(f\"Using {CURRENT_SIZE} dataset: {len(train_data):,} sentences\")\n",
    "print(f\"\\nFirst 3 training sentences:\")\n",
    "for i, sent in enumerate(train_data[:3]):\n",
    "    print(f\"{i+1}. {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data_header",
   "metadata": {},
   "source": [
    "## 5.4 Prepare Training Data for KenLM\n",
    "\n",
    "KenLM requires:\n",
    "1. Text file with one sentence per line\n",
    "2. We'll add sentence boundaries `<s>` and `</s>` (KenLM adds these automatically, but we can control it)\n",
    "3. Build model using `lmplz` command-line tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data to file for KenLM\n",
    "train_file = f'kenlm_train_{CURRENT_SIZE}.txt'\n",
    "\n",
    "print(f\"Writing training data to {train_file}...\")\n",
    "with open(train_file, 'w', encoding='utf-8') as f:\n",
    "    for sentence in train_data:\n",
    "        # KenLM automatically adds <s> and </s>, so we just write the sentence\n",
    "        f.write(sentence + '\\n')\n",
    "\n",
    "print(f\"Saved {len(train_data):,} sentences to {train_file}\")\n",
    "print(f\"File size: {os.path.getsize(train_file) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "build_model_header",
   "metadata": {},
   "source": [
    "## 5.5 Build KenLM Model\n",
    "\n",
    "We'll use `lmplz` to build a 5-gram model with Modified Kneser-Ney smoothing.\n",
    "\n",
    "**Command explanation:**\n",
    "- `-o 5`: Build 5-gram model\n",
    "- `--discount_fallback`: Handle edge cases in discounting\n",
    "- `-S 80%`: Use 80% of RAM for sorting (adjust if needed)\n",
    "- `-T /tmp`: Use /tmp for temporary files\n",
    "\n",
    "**Note:** This takes:\n",
    "- 10K: ~5-10 seconds\n",
    "- 100K: ~30-60 seconds\n",
    "- 1M: ~5-10 minutes\n",
    "- Full: ~30-60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build KenLM model\n",
    "model_file = f'kenlm_{CURRENT_SIZE}_5gram.arpa'\n",
    "\n",
    "print(f\"Building 5-gram KenLM model...\")\n",
    "print(f\"This may take a while for large datasets...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Build model using lmplz\n",
    "cmd = [\n",
    "    'lmplz',\n",
    "    '-o', '5',  # 5-gram\n",
    "    '--discount_fallback',\n",
    "    '-S', '80%',  # Use 80% RAM\n",
    "    '-T', '/tmp',  # Temp directory\n",
    "]\n",
    "\n",
    "with open(train_file, 'r') as input_f:\n",
    "    with open(model_file, 'w') as output_f:\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            stdin=input_f,\n",
    "            stdout=output_f,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"✓ Model built successfully in {elapsed:.2f} seconds\")\n",
    "    print(f\"Model saved to: {model_file}\")\n",
    "    print(f\"Model size: {os.path.getsize(model_file) / (1024*1024):.2f} MB\")\n",
    "else:\n",
    "    print(f\"✗ Error building model:\")\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_model_header",
   "metadata": {},
   "source": [
    "## 5.6 Load KenLM Model\n",
    "\n",
    "Now we'll load the model into Python for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "print(f\"Loading KenLM model from {model_file}...\")\n",
    "model = kenlm.Model(model_file)\n",
    "\n",
    "print(f\"✓ Model loaded successfully!\")\n",
    "print(f\"Model order: {model.order}\")\n",
    "\n",
    "# Test the model\n",
    "test_sentence = \"the president of the united states\"\n",
    "score = model.score(test_sentence, bos=True, eos=True)\n",
    "perplexity = model.perplexity(test_sentence)\n",
    "\n",
    "print(f\"\\nTest sentence: '{test_sentence}'\")\n",
    "print(f\"Log10 probability: {score:.4f}\")\n",
    "print(f\"Perplexity: {perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "build_vocab_header",
   "metadata": {},
   "source": [
    "## 5.7 Build Vocabulary Index\n",
    "\n",
    "We need to index vocabulary by first letter for efficient candidate filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_vocab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from training data\n",
    "print(\"Building vocabulary index...\")\n",
    "\n",
    "vocab_by_first_char = defaultdict(set)\n",
    "\n",
    "for sentence in tqdm(train_data, desc=\"Indexing vocabulary\"):\n",
    "    tokens = sentence.split()\n",
    "    for token in tokens:\n",
    "        first_char = token[0]\n",
    "        vocab_by_first_char[first_char].add(token)\n",
    "\n",
    "print(f\"\\nVocabulary indexed by first character:\")\n",
    "print(f\"Total unique words: {sum(len(words) for words in vocab_by_first_char.values()):,}\")\n",
    "print(f\"Number of first characters: {len(vocab_by_first_char)}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample: Words starting with 'a': {len(vocab_by_first_char['a']):,}\")\n",
    "print(f\"Sample: Words starting with 't': {len(vocab_by_first_char['t']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction_header",
   "metadata": {},
   "source": [
    "## 5.8 Prediction Function\n",
    "\n",
    "We'll score all candidate words and select the one with highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prediction_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(context: str, first_letter: str, model: kenlm.Model, vocab_by_first_char: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Predict next word given context and first letter constraint.\n",
    "    \n",
    "    Args:\n",
    "        context: Previous words as string (e.g., \"the cat sat on the\")\n",
    "        first_letter: Required first character of prediction\n",
    "        model: KenLM model\n",
    "        vocab_by_first_char: Dictionary mapping first char to set of words\n",
    "    \n",
    "    Returns:\n",
    "        Predicted word (most likely word starting with first_letter)\n",
    "    \"\"\"\n",
    "    # Get candidate words\n",
    "    candidates = vocab_by_first_char.get(first_letter, set())\n",
    "    \n",
    "    if not candidates:\n",
    "        # No words in vocabulary start with this letter\n",
    "        return first_letter\n",
    "    \n",
    "    # Score each candidate\n",
    "    best_word = None\n",
    "    best_score = float('-inf')\n",
    "    \n",
    "    for word in candidates:\n",
    "        # Create full sentence with candidate word\n",
    "        full_sentence = context + ' ' + word if context else word\n",
    "        \n",
    "        # Score with KenLM\n",
    "        # We use bos=True to add <s>, eos=False since we're predicting next word\n",
    "        score = model.score(full_sentence, bos=True, eos=False)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_word = word\n",
    "    \n",
    "    return best_word if best_word else first_letter\n",
    "\n",
    "print(\"Prediction function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_predictions_header",
   "metadata": {},
   "source": [
    "## 5.9 Test Predictions\n",
    "\n",
    "Let's test on a few manual examples before evaluating on dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test examples\n",
    "test_cases = [\n",
    "    (\"the cat sat on the\", \"m\"),  # mat?\n",
    "    (\"president of the united\", \"s\"),  # states?\n",
    "    (\"new york\", \"c\"),  # city?\n",
    "    (\"in the\", \"m\"),  # morning? middle?\n",
    "    (\"on\", \"m\"),  # monday?\n",
    "]\n",
    "\n",
    "print(\"Testing predictions:\\n\")\n",
    "for context, first_letter in test_cases:\n",
    "    prediction = predict(context, first_letter, model, vocab_by_first_char)\n",
    "    print(f\"Context: '{context}'\")\n",
    "    print(f\"First letter: '{first_letter}'\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate_header",
   "metadata": {},
   "source": [
    "## 5.10 Evaluate on Dev Set\n",
    "\n",
    "Now let's evaluate on the full development set (all 94,825 examples).\n",
    "\n",
    "**Note:** This may take 5-10 minutes depending on dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_dev",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on dev set\n",
    "print(f\"\\nEvaluating on development set...\")\n",
    "\n",
    "# For testing, you can limit examples\n",
    "max_examples = None  # Set to 1000 for quick testing\n",
    "eval_df = dev_df.head(max_examples) if max_examples else dev_df\n",
    "\n",
    "correct = 0\n",
    "total = len(eval_df)\n",
    "predictions = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, row in tqdm(eval_df.iterrows(), total=total, desc=\"Predicting\"):\n",
    "    context = row['context']\n",
    "    first_letter = row['first letter']\n",
    "    answer = row['answer']\n",
    "    \n",
    "    # Predict\n",
    "    prediction = predict(context, first_letter, model, vocab_by_first_char)\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    # Check correctness\n",
    "    if prediction == answer:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Total examples: {total:,}\")\n",
    "print(f\"  Correct: {correct:,}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  Time: {elapsed:.2f} seconds ({elapsed/total*1000:.2f} ms/prediction)\")\n",
    "\n",
    "print(f\"\\nExpected accuracy for {CURRENT_SIZE} dataset: ~25-30%\")\n",
    "print(f\"Actual accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis_header",
   "metadata": {},
   "source": [
    "## 5.11 Error Analysis\n",
    "\n",
    "Let's look at some examples where the model got it right vs wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "error_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dev_df\n",
    "dev_sample = eval_df.copy()\n",
    "dev_sample['prediction'] = predictions\n",
    "dev_sample['correct'] = dev_sample['prediction'] == dev_sample['answer']\n",
    "\n",
    "# Show correct predictions\n",
    "print(\"=\"*80)\n",
    "print(\"CORRECT PREDICTIONS (Sample of 5)\")\n",
    "print(\"=\"*80)\n",
    "correct_samples = dev_sample[dev_sample['correct']].head(5)\n",
    "for idx, row in correct_samples.iterrows():\n",
    "    print(f\"\\nContext: {row['context']}\")\n",
    "    print(f\"First letter: '{row['first letter']}'\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Answer: {row['answer']}\")\n",
    "    print(f\"✓ CORRECT\")\n",
    "\n",
    "# Show incorrect predictions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INCORRECT PREDICTIONS (Sample of 5)\")\n",
    "print(\"=\"*80)\n",
    "incorrect_samples = dev_sample[~dev_sample['correct']].head(5)\n",
    "for idx, row in incorrect_samples.iterrows():\n",
    "    print(f\"\\nContext: {row['context']}\")\n",
    "    print(f\"First letter: '{row['first letter']}'\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Answer: {row['answer']}\")\n",
    "    print(f\"✗ INCORRECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling_header",
   "metadata": {},
   "source": [
    "## 5.12 Scaling Experiments\n",
    "\n",
    "Now let's see how accuracy changes with more training data.\n",
    "\n",
    "**Note:** This will take progressively longer:\n",
    "- 10K: ~1-2 minutes total\n",
    "- 100K: ~5-10 minutes total\n",
    "- 1M: ~20-30 minutes total\n",
    "- Full (3.8M): ~1-2 hours total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scaling_experiments",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run experiments on different data sizes\n",
    "# # Uncomment to run scaling experiments\n",
    "# sizes_to_test = [\n",
    "#     'debug',   # 10K\n",
    "#     # 'dev',     # 100K\n",
    "#     # 'large',   # 1M\n",
    "#     # 'full',    # 3.8M\n",
    "# ]\n",
    "\n",
    "# scaling_results = []\n",
    "\n",
    "# for size_key in sizes_to_test:\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(f\"TRAINING ON {size_key.upper()} DATASET ({DATA_SIZES[size_key]:,} sentences)\")\n",
    "#     print(\"=\"*80)\n",
    "    \n",
    "#     # Sample data\n",
    "#     data = sample_data(train_lines, size_key)\n",
    "    \n",
    "#     # Prepare training file\n",
    "#     train_file = f'kenlm_train_{size_key}.txt'\n",
    "#     with open(train_file, 'w', encoding='utf-8') as f:\n",
    "#         for sentence in data:\n",
    "#             f.write(sentence + '\\n')\n",
    "    \n",
    "#     # Build model\n",
    "#     model_file = f'kenlm_{size_key}_5gram.arpa'\n",
    "#     cmd = ['lmplz', '-o', '5', '--discount_fallback', '-S', '80%', '-T', '/tmp']\n",
    "    \n",
    "#     with open(train_file, 'r') as input_f:\n",
    "#         with open(model_file, 'w') as output_f:\n",
    "#             subprocess.run(cmd, stdin=input_f, stdout=output_f, stderr=subprocess.PIPE)\n",
    "    \n",
    "#     # Load model\n",
    "#     model = kenlm.Model(model_file)\n",
    "    \n",
    "#     # Build vocabulary\n",
    "#     vocab = defaultdict(set)\n",
    "#     for sentence in data:\n",
    "#         for token in sentence.split():\n",
    "#             vocab[token[0]].add(token)\n",
    "    \n",
    "#     # Evaluate (use sample for speed)\n",
    "#     eval_sample = dev_df.head(1000)  # Use 1000 for faster testing\n",
    "#     correct = 0\n",
    "#     for idx, row in eval_sample.iterrows():\n",
    "#         pred = predict(row['context'], row['first letter'], model, vocab)\n",
    "#         if pred == row['answer']:\n",
    "#             correct += 1\n",
    "    \n",
    "#     accuracy = correct / len(eval_sample)\n",
    "    \n",
    "#     # Store results\n",
    "#     scaling_results.append({\n",
    "#         'size': size_key,\n",
    "#         'num_sentences': len(data),\n",
    "#         'accuracy': accuracy\n",
    "#     })\n",
    "\n",
    "# # Show summary\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"SCALING RESULTS SUMMARY\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"{'Dataset':<15} {'# Sentences':<15} {'Accuracy':<15}\")\n",
    "# print(\"-\"*45)\n",
    "# for result in scaling_results:\n",
    "#     print(f\"{result['size']:<15} {result['num_sentences']:<15,} {result['accuracy']*100:<14.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps_header",
   "metadata": {},
   "source": [
    "## 5.13 Next Steps\n",
    "\n",
    "**Current Status:**\n",
    "- ✅ Trigram model implemented (58.12% on full data)\n",
    "- ✅ 4-gram model implemented\n",
    "- ✅ 5-gram model implemented\n",
    "- ✅ KenLM with Kneser-Ney implemented\n",
    "- ✅ Best n-gram baseline complete\n",
    "\n",
    "**KenLM vs Our Models:**\n",
    "- Our 5-gram: Simple MLE with backoff\n",
    "- KenLM: Modified Kneser-Ney smoothing (better generalization)\n",
    "- Expected improvement: +3-8% over our 5-gram\n",
    "\n",
    "**To improve further:**\n",
    "\n",
    "1. **Neural Models**: LSTM/GRU\n",
    "   - Expected: 60-70% accuracy\n",
    "   - Can capture longer dependencies\n",
    "\n",
    "2. **Fine-tune GPT-2**: Transformer-based\n",
    "   - Expected: 65-75% accuracy\n",
    "   - Best single model performance\n",
    "\n",
    "3. **Ensemble**: Combine KenLM + LSTM + GPT-2\n",
    "   - Expected: 70-80% accuracy\n",
    "   - Weighted voting or stacking\n",
    "\n",
    "**Next notebook:**\n",
    "- `6_LSTM.ipynb` - Implement LSTM from scratch\n",
    "- Or `7_GPT2.ipynb` - Fine-tune GPT-2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
