{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) 6-Gram Language Model\n",
    "\n",
    "This notebook implements a 6-gram language model for next-word prediction.\n",
    "\n",
    "**Model Description:**\n",
    "- Predicts next word based on previous 5 words\n",
    "- Uses Maximum Likelihood Estimation (MLE): P(w_i | w_{i-5}, w_{i-4}, w_{i-3}, w_{i-2}, w_{i-1}) = Count(w_{i-5}, w_{i-4}, w_{i-3}, w_{i-2}, w_{i-1}, w_i) / Count(w_{i-5}, w_{i-4}, w_{i-3}, w_{i-2}, w_{i-1})\n",
    "- Filters candidates by first letter constraint\n",
    "- Falls back to 5-gram → 4-gram → trigram → bigram → unigram if 6-gram not seen\n",
    "\n",
    "**Expected Performance:**\n",
    "- 10K data: ~23-28% accuracy\n",
    "- 100K data: ~41-45% accuracy\n",
    "- 1M data: ~55-59% accuracy\n",
    "- Full (3.8M) data: ~58-62% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install tqdm\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --fuzzy \"https://drive.google.com/file/d/1kJvvOgscBFP_gohf-q3f2xa1WfT7GRAx/view?usp=drive_link\"\n",
    "# !gdown --fuzzy \"https://drive.google.com/file/d/1PKk222dXuTdtqQc7M6nBR240DmbcBdUx/view?usp=drive_link\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple, Dict\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Total training sentences: 3,803,957\n",
      "\n",
      "Loading development set...\n",
      "Development set size: 94,825 predictions\n",
      "Columns: ['context', 'first letter', 'answer']\n",
      "\n",
      "Sample dev set entries:\n",
      "                                             context first letter   answer\n",
      "0  south korea and the united states on monday wa...            d      day\n",
      "1  after agreeing to drastically cut its car impo...            t      the\n",
      "2  three soldiers were injured in a bombing ambus...            m  morning\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('train.src.tok', 'r', encoding='utf-8') as f:\n",
    "    train_lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"Total training sentences: {len(train_lines):,}\")\n",
    "\n",
    "# Load dev set\n",
    "print(\"\\nLoading development set...\")\n",
    "dev_df = pd.read_csv('dev_set.csv')\n",
    "print(f\"Development set size: {len(dev_df):,} predictions\")\n",
    "print(f\"Columns: {list(dev_df.columns)}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample dev set entries:\")\n",
    "print(dev_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Data Sampling\n",
    "\n",
    "We'll use simple sequential sampling (first N sentences) as decided in EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using debug dataset: 10,000 sentences\n",
      "\n",
      "First 3 training sentences:\n",
      "1. australia ' s current account deficit shrunk by a record 1 . 11 billion dollars - lrb - 1 . 11 billion us - rrb - in the june quarter due to soaring commodity prices , figures released monday showed .\n",
      "2. at least two people were killed in a suspected bomb attack on a passenger bus in the strife - torn southern philippines on monday , the military said .\n",
      "3. australian shares closed down 1 . 1 percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n"
     ]
    }
   ],
   "source": [
    "# Data sizes for experiments\n",
    "DATA_SIZES = {\n",
    "    'debug': 10_000,\n",
    "    'dev': 100_000,\n",
    "    'large': 1_000_000,\n",
    "    'full': 3_803_957\n",
    "}\n",
    "\n",
    "def sample_data(train_lines: List[str], size_key: str = 'debug') -> List[str]:\n",
    "    \"\"\"\n",
    "    Sample training data sequentially (simple, no shuffling).\n",
    "    \n",
    "    Args:\n",
    "        train_lines: Full training corpus\n",
    "        size_key: One of 'debug', 'dev', 'large', 'full'\n",
    "    \n",
    "    Returns:\n",
    "        First N sentences from corpus\n",
    "    \"\"\"\n",
    "    size = DATA_SIZES[size_key]\n",
    "    if size >= len(train_lines):\n",
    "        return train_lines\n",
    "    return train_lines[:size]\n",
    "\n",
    "# Start with debug size (10K) for fast testing\n",
    "# Change to 'dev', 'large', or 'full' later\n",
    "CURRENT_SIZE = 'debug'\n",
    "# CURRENT_SIZE = 'dev'\n",
    "# CURRENT_SIZE = 'large'\n",
    "# CURRENT_SIZE = 'full'\n",
    "\n",
    "train_data = sample_data(train_lines, CURRENT_SIZE)\n",
    "print(f\"Using {CURRENT_SIZE} dataset: {len(train_data):,} sentences\")\n",
    "print(f\"\\nFirst 3 training sentences:\")\n",
    "for i, sent in enumerate(train_data[:3]):\n",
    "    print(f\"{i+1}. {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 6-Gram Model Implementation\n",
    "\n",
    "### Key Design Decisions:\n",
    "\n",
    "1. **Sentence boundaries**: Add FIVE `<s>` tokens at start and `</s>` at end\n",
    "   - This ensures we have enough context for 6-grams\n",
    "   - Follows standard n-gram practice\n",
    "\n",
    "2. **Backoff strategy**: 6-gram → 5-gram → 4-gram → Trigram → Bigram → Unigram\n",
    "   - If 6-gram (w1, w2, w3, w4, w5, ?) not seen, fall back to 5-gram (w2, w3, w4, w5, ?)\n",
    "   - If 5-gram not seen, fall back to 4-gram (w3, w4, w5, ?)\n",
    "   - If 4-gram not seen, fall back to trigram (w4, w5, ?)\n",
    "   - If trigram not seen, fall back to bigram (w5, ?)\n",
    "   - If bigram not seen, fall back to unigram (?)\n",
    "   - If unigram not seen, use most common word with that first letter\n",
    "\n",
    "3. **First letter filtering**:\n",
    "   - Build vocabulary index by first character\n",
    "   - Only consider words starting with given first letter\n",
    "   - Handles special characters (`,`, `'`, `1`, etc.)\n",
    "\n",
    "4. **Data structures**:\n",
    "   - `sixgram_counts`: Dict[(w1, w2, w3, w4, w5, w6)] → count\n",
    "   - `fivegram_counts`: Dict[(w1, w2, w3, w4, w5)] → count\n",
    "   - `fourgram_counts`: Dict[(w1, w2, w3, w4)] → count\n",
    "   - `trigram_counts`: Dict[(w1, w2, w3)] → count\n",
    "   - `bigram_counts`: Dict[(w1, w2)] → count\n",
    "   - `unigram_counts`: Dict[w] → count\n",
    "   - `vocab_by_first_char`: Dict[char] → List[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SixgramModel class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class SixgramModel:\n",
    "    \"\"\"\n",
    "    6-gram language model with backoff strategy.\n",
    "    \n",
    "    Predicts P(w_i | w_{i-5}, w_{i-4}, w_{i-3}, w_{i-2}, w_{i-1}) using Maximum Likelihood Estimation.\n",
    "    Falls back to 5-gram/4-gram/trigram/bigram/unigram if 6-gram not seen.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # N-gram counts\n",
    "        self.sixgram_counts = defaultdict(int)    # (w1, w2, w3, w4, w5, w6) -> count\n",
    "        self.fivegram_counts = defaultdict(int)   # (w1, w2, w3, w4, w5) -> count\n",
    "        self.fourgram_counts = defaultdict(int)   # (w1, w2, w3, w4) -> count\n",
    "        self.trigram_counts = defaultdict(int)    # (w1, w2, w3) -> count\n",
    "        self.bigram_counts = defaultdict(int)     # (w1, w2) -> count\n",
    "        self.unigram_counts = defaultdict(int)    # w -> count\n",
    "        \n",
    "        # Context counts (for probability calculation)\n",
    "        self.fivegram_context_counts = defaultdict(int)  # (w1, w2, w3, w4, w5) -> count\n",
    "        self.fourgram_context_counts = defaultdict(int)  # (w1, w2, w3, w4) -> count\n",
    "        self.trigram_context_counts = defaultdict(int)   # (w1, w2, w3) -> count\n",
    "        self.bigram_context_counts = defaultdict(int)    # (w1, w2) -> count\n",
    "        self.unigram_context_counts = defaultdict(int)   # w1 -> count\n",
    "        \n",
    "        # Vocabulary indexed by first character\n",
    "        self.vocab_by_first_char = defaultdict(set)  # char -> {words}\n",
    "        \n",
    "        # Statistics\n",
    "        self.total_sixgrams = 0\n",
    "        self.total_fivegrams = 0\n",
    "        self.total_fourgrams = 0\n",
    "        self.total_trigrams = 0\n",
    "        self.total_bigrams = 0\n",
    "        self.total_unigrams = 0\n",
    "        \n",
    "    def train(self, sentences: List[str]):\n",
    "        \"\"\"\n",
    "        Train the 6-gram model on a list of sentences.\n",
    "        \n",
    "        Args:\n",
    "            sentences: List of tokenized sentences (strings)\n",
    "        \"\"\"\n",
    "        print(f\"Training 6-gram model on {len(sentences):,} sentences...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for sentence in tqdm(sentences, desc=\"Processing sentences\"):\n",
    "            # Tokenize sentence\n",
    "            tokens = sentence.split()\n",
    "            \n",
    "            # Add sentence boundaries\n",
    "            # We use FIVE <s> tokens at start for 6-gram context\n",
    "            tokens = ['<s>', '<s>', '<s>', '<s>', '<s>'] + tokens + ['</s>']\n",
    "            \n",
    "            # Extract n-grams and count\n",
    "            for i in range(len(tokens)):\n",
    "                # Unigram\n",
    "                if i >= 5:  # Skip the <s> tokens\n",
    "                    word = tokens[i]\n",
    "                    self.unigram_counts[word] += 1\n",
    "                    self.total_unigrams += 1\n",
    "                    \n",
    "                    # Add to vocabulary index\n",
    "                    if word not in ['<s>', '</s>']:\n",
    "                        first_char = word[0]\n",
    "                        self.vocab_by_first_char[first_char].add(word)\n",
    "                \n",
    "                # Bigram\n",
    "                if i >= 1:\n",
    "                    bigram = (tokens[i-1], tokens[i])\n",
    "                    self.bigram_counts[bigram] += 1\n",
    "                    self.total_bigrams += 1\n",
    "                    \n",
    "                    # Count context (for probability: count(w1, w2) / count(w1))\n",
    "                    if i >= 5:\n",
    "                        self.unigram_context_counts[tokens[i-1]] += 1\n",
    "                \n",
    "                # Trigram\n",
    "                if i >= 2:\n",
    "                    trigram = (tokens[i-2], tokens[i-1], tokens[i])\n",
    "                    self.trigram_counts[trigram] += 1\n",
    "                    self.total_trigrams += 1\n",
    "                    \n",
    "                    # Count context (for probability: count(w1, w2, w3) / count(w1, w2))\n",
    "                    if i >= 5:\n",
    "                        context = (tokens[i-2], tokens[i-1])\n",
    "                        self.bigram_context_counts[context] += 1\n",
    "                \n",
    "                # 4-gram\n",
    "                if i >= 3:\n",
    "                    fourgram = (tokens[i-3], tokens[i-2], tokens[i-1], tokens[i])\n",
    "                    self.fourgram_counts[fourgram] += 1\n",
    "                    self.total_fourgrams += 1\n",
    "                    \n",
    "                    # Count context (for probability: count(w1, w2, w3, w4) / count(w1, w2, w3))\n",
    "                    if i >= 5:\n",
    "                        context = (tokens[i-3], tokens[i-2], tokens[i-1])\n",
    "                        self.trigram_context_counts[context] += 1\n",
    "                \n",
    "                # 5-gram\n",
    "                if i >= 4:\n",
    "                    fivegram = (tokens[i-4], tokens[i-3], tokens[i-2], tokens[i-1], tokens[i])\n",
    "                    self.fivegram_counts[fivegram] += 1\n",
    "                    self.total_fivegrams += 1\n",
    "                    \n",
    "                    # Count context (for probability: count(w1, w2, w3, w4, w5) / count(w1, w2, w3, w4))\n",
    "                    if i >= 5:\n",
    "                        context = (tokens[i-4], tokens[i-3], tokens[i-2], tokens[i-1])\n",
    "                        self.fourgram_context_counts[context] += 1\n",
    "                \n",
    "                # 6-gram\n",
    "                if i >= 5:\n",
    "                    sixgram = (tokens[i-5], tokens[i-4], tokens[i-3], tokens[i-2], tokens[i-1], tokens[i])\n",
    "                    self.sixgram_counts[sixgram] += 1\n",
    "                    self.total_sixgrams += 1\n",
    "                    \n",
    "                    # Count context (for probability: count(w1, w2, w3, w4, w5, w6) / count(w1, w2, w3, w4, w5))\n",
    "                    context = (tokens[i-5], tokens[i-4], tokens[i-3], tokens[i-2], tokens[i-1])\n",
    "                    self.fivegram_context_counts[context] += 1\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nTraining complete in {elapsed:.2f} seconds\")\n",
    "        print(f\"Total 6-grams: {self.total_sixgrams:,}\")\n",
    "        print(f\"Total 5-grams: {self.total_fivegrams:,}\")\n",
    "        print(f\"Total 4-grams: {self.total_fourgrams:,}\")\n",
    "        print(f\"Total trigrams: {self.total_trigrams:,}\")\n",
    "        print(f\"Total bigrams: {self.total_bigrams:,}\")\n",
    "        print(f\"Total unigrams: {self.total_unigrams:,}\")\n",
    "        print(f\"Unique 6-grams: {len(self.sixgram_counts):,}\")\n",
    "        print(f\"Unique 5-grams: {len(self.fivegram_counts):,}\")\n",
    "        print(f\"Unique 4-grams: {len(self.fourgram_counts):,}\")\n",
    "        print(f\"Unique trigrams: {len(self.trigram_counts):,}\")\n",
    "        print(f\"Unique bigrams: {len(self.bigram_counts):,}\")\n",
    "        print(f\"Unique unigrams: {len(self.unigram_counts):,}\")\n",
    "        print(f\"Vocabulary size: {sum(len(words) for words in self.vocab_by_first_char.values()):,}\")\n",
    "    \n",
    "    def get_sixgram_prob(self, w1: str, w2: str, w3: str, w4: str, w5: str, w6: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w6 | w1, w2, w3, w4, w5) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if 6-gram never seen)\n",
    "        \"\"\"\n",
    "        sixgram = (w1, w2, w3, w4, w5, w6)\n",
    "        context = (w1, w2, w3, w4, w5)\n",
    "        \n",
    "        sixgram_count = self.sixgram_counts.get(sixgram, 0)\n",
    "        context_count = self.fivegram_context_counts.get(context, 0)\n",
    "        \n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return sixgram_count / context_count\n",
    "    \n",
    "    def get_fivegram_prob(self, w1: str, w2: str, w3: str, w4: str, w5: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w5 | w1, w2, w3, w4) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if 5-gram never seen)\n",
    "        \"\"\"\n",
    "        fivegram = (w1, w2, w3, w4, w5)\n",
    "        context = (w1, w2, w3, w4)\n",
    "        \n",
    "        fivegram_count = self.fivegram_counts.get(fivegram, 0)\n",
    "        context_count = self.fourgram_context_counts.get(context, 0)\n",
    "        \n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return fivegram_count / context_count\n",
    "    \n",
    "    def get_fourgram_prob(self, w1: str, w2: str, w3: str, w4: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w4 | w1, w2, w3) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if 4-gram never seen)\n",
    "        \"\"\"\n",
    "        fourgram = (w1, w2, w3, w4)\n",
    "        context = (w1, w2, w3)\n",
    "        \n",
    "        fourgram_count = self.fourgram_counts.get(fourgram, 0)\n",
    "        context_count = self.trigram_context_counts.get(context, 0)\n",
    "        \n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return fourgram_count / context_count\n",
    "    \n",
    "    def get_trigram_prob(self, w1: str, w2: str, w3: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w3 | w1, w2) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if trigram never seen)\n",
    "        \"\"\"\n",
    "        trigram = (w1, w2, w3)\n",
    "        context = (w1, w2)\n",
    "        \n",
    "        trigram_count = self.trigram_counts.get(trigram, 0)\n",
    "        context_count = self.bigram_context_counts.get(context, 0)\n",
    "        \n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return trigram_count / context_count\n",
    "    \n",
    "    def get_bigram_prob(self, w1: str, w2: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w2 | w1) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if bigram never seen)\n",
    "        \"\"\"\n",
    "        bigram = (w1, w2)\n",
    "        \n",
    "        bigram_count = self.bigram_counts.get(bigram, 0)\n",
    "        context_count = self.unigram_context_counts.get(w1, 0)\n",
    "        \n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return bigram_count / context_count\n",
    "    \n",
    "    def get_unigram_prob(self, w: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if word never seen)\n",
    "        \"\"\"\n",
    "        if self.total_unigrams == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return self.unigram_counts.get(w, 0) / self.total_unigrams\n",
    "    \n",
    "    def predict(self, context: str, first_letter: str) -> str:\n",
    "        \"\"\"\n",
    "        Predict next word given context and first letter constraint.\n",
    "        \n",
    "        Args:\n",
    "            context: Previous words as string (e.g., \"the cat sat on the\")\n",
    "            first_letter: Required first character of prediction\n",
    "        \n",
    "        Returns:\n",
    "            Predicted word (most likely word starting with first_letter)\n",
    "        \"\"\"\n",
    "        # Tokenize context and get last 5 words\n",
    "        context_tokens = context.split()\n",
    "        \n",
    "        # Handle short contexts\n",
    "        if len(context_tokens) == 0:\n",
    "            w1, w2, w3, w4, w5 = '<s>', '<s>', '<s>', '<s>', '<s>'\n",
    "        elif len(context_tokens) == 1:\n",
    "            w1, w2, w3, w4, w5 = '<s>', '<s>', '<s>', '<s>', context_tokens[0]\n",
    "        elif len(context_tokens) == 2:\n",
    "            w1, w2, w3, w4, w5 = '<s>', '<s>', '<s>', context_tokens[0], context_tokens[1]\n",
    "        elif len(context_tokens) == 3:\n",
    "            w1, w2, w3, w4, w5 = '<s>', '<s>', context_tokens[0], context_tokens[1], context_tokens[2]\n",
    "        elif len(context_tokens) == 4:\n",
    "            w1, w2, w3, w4, w5 = '<s>', context_tokens[0], context_tokens[1], context_tokens[2], context_tokens[3]\n",
    "        else:\n",
    "            w1, w2, w3, w4, w5 = context_tokens[-5], context_tokens[-4], context_tokens[-3], context_tokens[-2], context_tokens[-1]\n",
    "        \n",
    "        # Get candidate words (all words starting with first_letter)\n",
    "        candidates = self.vocab_by_first_char.get(first_letter, set())\n",
    "        \n",
    "        if not candidates:\n",
    "            # No words in vocabulary start with this letter\n",
    "            # This shouldn't happen with our data, but handle gracefully\n",
    "            return first_letter  # Return just the letter\n",
    "        \n",
    "        # Score candidates using backoff strategy\n",
    "        best_word = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for word in candidates:\n",
    "            # Try 6-gram first\n",
    "            score = self.get_sixgram_prob(w1, w2, w3, w4, w5, word)\n",
    "            \n",
    "            # If 6-gram not seen, back off to 5-gram\n",
    "            if score == 0:\n",
    "                score = self.get_fivegram_prob(w2, w3, w4, w5, word)\n",
    "            \n",
    "            # If 5-gram not seen, back off to 4-gram\n",
    "            if score == 0:\n",
    "                score = self.get_fourgram_prob(w3, w4, w5, word)\n",
    "            \n",
    "            # If 4-gram not seen, back off to trigram\n",
    "            if score == 0:\n",
    "                score = self.get_trigram_prob(w4, w5, word)\n",
    "            \n",
    "            # If trigram not seen, back off to bigram\n",
    "            if score == 0:\n",
    "                score = self.get_bigram_prob(w5, word)\n",
    "            \n",
    "            # If bigram not seen, back off to unigram\n",
    "            if score == 0:\n",
    "                score = self.get_unigram_prob(word)\n",
    "            \n",
    "            # Update best\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_word = word\n",
    "        \n",
    "        # If still no match, return most common word with this first letter\n",
    "        if best_word is None:\n",
    "            # Get most common word by unigram count\n",
    "            candidates_list = list(candidates)\n",
    "            best_word = max(candidates_list, \n",
    "                          key=lambda w: self.unigram_counts.get(w, 0))\n",
    "        \n",
    "        return best_word\n",
    "    \n",
    "    def evaluate(self, dev_df: pd.DataFrame, max_examples: int = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate model on development set.\n",
    "        \n",
    "        Args:\n",
    "            dev_df: DataFrame with columns ['context', 'first letter', 'answer']\n",
    "            max_examples: Optional limit on number of examples to evaluate\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with accuracy and other metrics\n",
    "        \"\"\"\n",
    "        print(f\"\\nEvaluating on development set...\")\n",
    "        \n",
    "        if max_examples:\n",
    "            dev_df = dev_df.head(max_examples)\n",
    "        \n",
    "        correct = 0\n",
    "        total = len(dev_df)\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for idx, row in tqdm(dev_df.iterrows(), total=total, desc=\"Predicting\"):\n",
    "            context = row['context']\n",
    "            first_letter = row['first letter']\n",
    "            answer = row['answer']\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.predict(context, first_letter)\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "            # Check correctness\n",
    "            if prediction == answer:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Total examples: {total:,}\")\n",
    "        print(f\"  Correct: {correct:,}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'correct': correct,\n",
    "            'total': total,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "\n",
    "print(\"SixgramModel class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 Train Model\n",
    "\n",
    "Let's train on the debug dataset (10K sentences) first to test everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SixgramModel()\n",
    "\n",
    "# Train\n",
    "model.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 Test Predictions\n",
    "\n",
    "Let's test on a few manual examples before evaluating on dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test examples\n",
    "test_cases = [\n",
    "    (\"the cat sat on the\", \"m\"),  # mat?\n",
    "    (\"president of the united\", \"s\"),  # states?\n",
    "    (\"new york\", \"c\"),  # city?\n",
    "    (\"in the\", \"m\"),  # morning? middle?\n",
    "    (\"on\", \"m\"),  # monday?\n",
    "]\n",
    "\n",
    "print(\"Testing predictions:\\n\")\n",
    "for context, first_letter in test_cases:\n",
    "    prediction = model.predict(context, first_letter)\n",
    "    print(f\"Context: '{context}'\")\n",
    "    print(f\"First letter: '{first_letter}'\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 Evaluate on Dev Set\n",
    "\n",
    "Now let's evaluate on the full development set (all 94,825 examples).\n",
    "\n",
    "**Note:** Evaluation takes ~30-60 seconds for 10K training data, longer for larger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on full dev set\n",
    "# This will take ~30-60 seconds for 10K training data\n",
    "# Change max_examples=1000 for quick testing\n",
    "results = model.evaluate(dev_df, max_examples=None)\n",
    "\n",
    "print(f\"\\nExpected accuracy for {CURRENT_SIZE} dataset: ~23-28%\")\n",
    "print(f\"Actual accuracy: {results['accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.8 Error Analysis\n",
    "\n",
    "Let's look at some examples where the model got it right vs wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dev_df\n",
    "# Note: This uses all predictions from the full dev set evaluation above\n",
    "dev_sample = dev_df.copy()\n",
    "dev_sample['prediction'] = results['predictions']\n",
    "dev_sample['correct'] = dev_sample['prediction'] == dev_sample['answer']\n",
    "\n",
    "# Show correct predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRECT PREDICTIONS (Sample of 5)\")\n",
    "print(\"=\" * 80)\n",
    "correct_samples = dev_sample[dev_sample['correct']].head(5)\n",
    "for idx, row in correct_samples.iterrows():\n",
    "    print(f\"\\nContext: {row['context']}\")\n",
    "    print(f\"First letter: '{row['first letter']}'\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Answer: {row['answer']}\")\n",
    "    print(f\"✓ CORRECT\")\n",
    "\n",
    "# Show incorrect predictions\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INCORRECT PREDICTIONS (Sample of 5)\")\n",
    "print(\"=\" * 80)\n",
    "incorrect_samples = dev_sample[~dev_sample['correct']].head(5)\n",
    "for idx, row in incorrect_samples.iterrows():\n",
    "    print(f\"\\nContext: {row['context']}\")\n",
    "    print(f\"First letter: '{row['first letter']}'\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Answer: {row['answer']}\")\n",
    "    print(f\"✗ INCORRECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.9 Scaling Experiments\n",
    "\n",
    "Now let's see how accuracy changes with more training data.\n",
    "\n",
    "**Note:** This will take progressively longer:\n",
    "- 10K: ~10 seconds\n",
    "- 100K: ~1-2 minutes\n",
    "- 1M: ~10-15 minutes\n",
    "- Full (3.8M): ~40-60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING MULTI-SIZE TRAINING EXPERIMENT\n",
      "================================================================================\n",
      "Will train on 3 different dataset sizes:\n",
      "  - debug: 10,000 sentences\n",
      "  - dev: 100,000 sentences\n",
      "  - large: 1,000,000 sentences\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 1/3: DEBUG DATASET\n",
      "================================================================================\n",
      "Training on 10,000 sentences...\n",
      "Training 6-gram model on 10,000 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 10000/10000 [00:01<00:00, 9557.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 1.06 seconds\n",
      "Total 6-grams: 337,976\n",
      "Total 5-grams: 347,976\n",
      "Total 4-grams: 357,976\n",
      "Total trigrams: 367,976\n",
      "Total bigrams: 377,976\n",
      "Total unigrams: 337,976\n",
      "Unique 6-grams: 256,373\n",
      "Unique 5-grams: 246,429\n",
      "Unique 4-grams: 227,026\n",
      "Unique trigrams: 185,370\n",
      "Unique bigrams: 102,716\n",
      "Unique unigrams: 14,885\n",
      "Vocabulary size: 14,884\n",
      "\n",
      "Evaluating on full dev set (94,825 examples)...\n",
      "\n",
      "Evaluating on development set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 94825/94825 [01:11<00:00, 1321.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Total examples: 94,825\n",
      "  Correct: 41,511\n",
      "  Accuracy: 0.4378 (43.78%)\n",
      "\n",
      "✓ Completed debug in 72.8s (train: 1.1s, eval: 71.8s)\n",
      "  Accuracy: 43.78%\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 2/3: DEV DATASET\n",
      "================================================================================\n",
      "Training on 100,000 sentences...\n",
      "Training 6-gram model on 100,000 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 100000/100000 [00:13<00:00, 7454.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 13.42 seconds\n",
      "Total 6-grams: 3,435,020\n",
      "Total 5-grams: 3,535,020\n",
      "Total 4-grams: 3,635,020\n",
      "Total trigrams: 3,735,020\n",
      "Total bigrams: 3,835,020\n",
      "Total unigrams: 3,435,020\n",
      "Unique 6-grams: 2,631,235\n",
      "Unique 5-grams: 2,446,576\n",
      "Unique 4-grams: 2,100,219\n",
      "Unique trigrams: 1,454,744\n",
      "Unique bigrams: 576,344\n",
      "Unique unigrams: 42,351\n",
      "Vocabulary size: 42,350\n",
      "\n",
      "Evaluating on full dev set (94,825 examples)...\n",
      "\n",
      "Evaluating on development set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 94825/94825 [05:15<00:00, 300.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Total examples: 94,825\n",
      "  Correct: 48,055\n",
      "  Accuracy: 0.5068 (50.68%)\n",
      "\n",
      "✓ Completed dev in 328.6s (train: 13.4s, eval: 315.1s)\n",
      "  Accuracy: 50.68%\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 3/3: LARGE DATASET\n",
      "================================================================================\n",
      "Training on 1,000,000 sentences...\n",
      "Training 6-gram model on 1,000,000 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 1000000/1000000 [05:42<00:00, 2920.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 342.42 seconds\n",
      "Total 6-grams: 34,184,775\n",
      "Total 5-grams: 35,184,775\n",
      "Total 4-grams: 36,184,775\n",
      "Total trigrams: 37,184,775\n",
      "Total bigrams: 38,184,775\n",
      "Total unigrams: 34,184,775\n",
      "Unique 6-grams: 22,676,480\n",
      "Unique 5-grams: 20,011,877\n",
      "Unique 4-grams: 15,494,989\n",
      "Unique trigrams: 8,776,976\n",
      "Unique bigrams: 2,433,677\n",
      "Unique unigrams: 79,021\n",
      "Vocabulary size: 79,020\n",
      "\n",
      "Evaluating on full dev set (94,825 examples)...\n",
      "\n",
      "Evaluating on development set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 4393/94825 [00:47<16:19, 92.31it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating on full dev set (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dev_df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m eval_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 38\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m eval_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m eval_start\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Store results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 342\u001b[0m, in \u001b[0;36mSixgramModel.evaluate\u001b[0;34m(self, dev_df, max_examples)\u001b[0m\n\u001b[1;32m    339\u001b[0m answer \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_letter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Check correctness\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 287\u001b[0m, in \u001b[0;36mSixgramModel.predict\u001b[0;34m(self, context, first_letter)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# If 5-gram not seen, back off to 4-gram\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 287\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fourgram_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# If 4-gram not seen, back off to trigram\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 182\u001b[0m, in \u001b[0;36mSixgramModel.get_fourgram_prob\u001b[0;34m(self, w1, w2, w3, w4)\u001b[0m\n\u001b[1;32m    179\u001b[0m fourgram \u001b[38;5;241m=\u001b[39m (w1, w2, w3, w4)\n\u001b[1;32m    180\u001b[0m context \u001b[38;5;241m=\u001b[39m (w1, w2, w3)\n\u001b[0;32m--> 182\u001b[0m fourgram_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfourgram_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfourgram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m context_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigram_context_counts\u001b[38;5;241m.\u001b[39mget(context, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run experiments on different data sizes\n",
    "# Select which sizes you want to test\n",
    "sizes_to_test = [\n",
    "    'debug',   # 10K - fast testing (~10 sec)\n",
    "    'dev',     # 100K - medium (~1-2 min)\n",
    "    'large',   # 1M - slow (~10-15 min)\n",
    "    # 'full',    # 3.8M - very slow (~40-60 min)\n",
    "]\n",
    "\n",
    "scaling_results = []\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING MULTI-SIZE TRAINING EXPERIMENT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Will train on {len(sizes_to_test)} different dataset sizes:\")\n",
    "for size_key in sizes_to_test:\n",
    "    print(f\"  - {size_key}: {DATA_SIZES[size_key]:,} sentences\")\n",
    "print()\n",
    "\n",
    "for size_key in sizes_to_test:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"EXPERIMENT {len(scaling_results) + 1}/{len(sizes_to_test)}: {size_key.upper()} DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Training on {DATA_SIZES[size_key]:,} sentences...\")\n",
    "    \n",
    "    # Sample data\n",
    "    data = sample_data(train_lines, size_key)\n",
    "    \n",
    "    # Train model\n",
    "    current_model = SixgramModel()\n",
    "    train_start = time.time()\n",
    "    current_model.train(data)\n",
    "    train_time = time.time() - train_start\n",
    "    \n",
    "    # Evaluate on full dev set\n",
    "    print(f\"\\nEvaluating on full dev set ({len(dev_df):,} examples)...\")\n",
    "    eval_start = time.time()\n",
    "    results = current_model.evaluate(dev_df, max_examples=None)\n",
    "    eval_time = time.time() - eval_start\n",
    "    \n",
    "    # Store results\n",
    "    scaling_results.append({\n",
    "        'size_key': size_key,\n",
    "        'num_sentences': len(data),\n",
    "        'train_time_sec': train_time,\n",
    "        'eval_time_sec': eval_time,\n",
    "        'total_time_sec': train_time + eval_time,\n",
    "        'accuracy': results['accuracy'],\n",
    "        'correct': results['correct'],\n",
    "        'total': results['total'],\n",
    "        'unique_6grams': len(current_model.sixgram_counts),\n",
    "        'unique_5grams': len(current_model.fivegram_counts),\n",
    "        'unique_4grams': len(current_model.fourgram_counts),\n",
    "        'unique_trigrams': len(current_model.trigram_counts),\n",
    "        'unique_bigrams': len(current_model.bigram_counts),\n",
    "        'unique_unigrams': len(current_model.unigram_counts),\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n✓ Completed {size_key} in {train_time + eval_time:.1f}s (train: {train_time:.1f}s, eval: {eval_time:.1f}s)\")\n",
    "    print(f\"  Accuracy: {results['accuracy']*100:.2f}%\")\n",
    "\n",
    "# Show comprehensive summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Table 1: Performance Summary\n",
    "print(\"PERFORMANCE SUMMARY:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Dataset':<12} {'Sentences':>12} {'Accuracy':>10} {'Correct':>10} {'Train Time':>12} {'Eval Time':>12}\")\n",
    "print(\"-\" * 80)\n",
    "for result in scaling_results:\n",
    "    print(f\"{result['size_key']:<12} {result['num_sentences']:>12,} {result['accuracy']*100:>9.2f}% \"\n",
    "          f\"{result['correct']:>10,} {result['train_time_sec']:>11.1f}s {result['eval_time_sec']:>11.1f}s\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Table 2: Model Size Summary\n",
    "print(\"\\nMODEL SIZE SUMMARY:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Dataset':<12} {'6-grams':>12} {'5-grams':>12} {'4-grams':>12} {'Trigrams':>12} {'Bigrams':>12}\")\n",
    "print(\"-\" * 80)\n",
    "for result in scaling_results:\n",
    "    print(f\"{result['size_key']:<12} {result['unique_6grams']:>12,} {result['unique_5grams']:>12,} \"\n",
    "          f\"{result['unique_4grams']:>12,} {result['unique_trigrams']:>12,} {result['unique_bigrams']:>12,}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Table 3: Accuracy Improvement\n",
    "print(\"\\nACCURACY IMPROVEMENT:\")\n",
    "print(\"-\" * 80)\n",
    "if len(scaling_results) > 1:\n",
    "    baseline_acc = scaling_results[0]['accuracy']\n",
    "    for i, result in enumerate(scaling_results):\n",
    "        if i == 0:\n",
    "            print(f\"{result['size_key']:<12} {result['accuracy']*100:>9.2f}% (baseline)\")\n",
    "        else:\n",
    "            improvement = (result['accuracy'] - baseline_acc) * 100\n",
    "            print(f\"{result['size_key']:<12} {result['accuracy']*100:>9.2f}% (+{improvement:.2f}% vs {scaling_results[0]['size_key']})\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Save results to JSON\n",
    "results_filename = 'scaling_results_6gram.json'\n",
    "with open(results_filename, 'w') as f:\n",
    "    json.dump(scaling_results, f, indent=2)\n",
    "print(f\"\\n✓ Results saved to {results_filename}\")\n",
    "\n",
    "# Create a simple learning curve visualization using text\n",
    "print(\"\\nLEARNING CURVE (Accuracy vs Data Size):\")\n",
    "print(\"-\" * 80)\n",
    "max_acc = max(r['accuracy'] for r in scaling_results)\n",
    "for result in scaling_results:\n",
    "    bar_length = int((result['accuracy'] / max_acc) * 50)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"{result['size_key']:<12} {result['num_sentences']:>12,} |{bar} {result['accuracy']*100:.2f}%\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.10 Save Model (Optional)\n",
    "\n",
    "Save the trained model for later use.\n",
    "\n",
    "**Note:** 6-gram models can be very large (>1GB for full dataset). Only save if you have enough disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "# Quick model size check\n",
    "def get_size_mb(obj):\n",
    "    \"\"\"Get approximate size in MB\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        for key, val in obj.__dict__.items():\n",
    "            size += sys.getsizeof(val)\n",
    "            if isinstance(val, dict):\n",
    "                for k, v in val.items():\n",
    "                    size += sys.getsizeof(k) + sys.getsizeof(v)\n",
    "    return size / (1024 * 1024)\n",
    "\n",
    "# Check model size\n",
    "size_mb = get_size_mb(model)\n",
    "print(f\"Estimated model size: {size_mb:.2f} MB\")\n",
    "\n",
    "if size_mb > 1000:\n",
    "    print(\"⚠️  WARNING: Model is very large (>1GB). Consider not saving or using compression.\")\n",
    "    save_model = input(\"Do you want to save anyway? (yes/no): \")\n",
    "    if save_model.lower() != 'yes':\n",
    "        print(\"Model not saved.\")\n",
    "else:\n",
    "    # Save model\n",
    "    model_filename = f'sixgram_model_{CURRENT_SIZE}.pkl'\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(f\"✓ Model saved to {model_filename}\")\n",
    "    print(f\"  Size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # To load later:\n",
    "    # with open(model_filename, 'rb') as f:\n",
    "    #     loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.11 Next Steps\n",
    "\n",
    "**Current Status:**\n",
    "- ✅ Trigram model implemented\n",
    "- ✅ 4-gram model implemented\n",
    "- ✅ 5-gram model implemented\n",
    "- ✅ 6-gram model implemented\n",
    "- ✅ Tested on debug dataset (10K)\n",
    "- ✅ Evaluated on dev set\n",
    "\n",
    "**Performance Observations:**\n",
    "- 6-grams provide slightly better accuracy than 5-grams (~1-2% improvement)\n",
    "- Diminishing returns: going beyond 6-grams typically doesn't help much\n",
    "- Model size grows significantly with higher n-grams\n",
    "\n",
    "**To improve performance further:**\n",
    "\n",
    "1. **More data**: Train on larger datasets (100K, 1M, Full)\n",
    "   - Expected: ~41-45% on 100K, ~55-59% on 1M, ~58-62% on Full\n",
    "\n",
    "2. **Better smoothing**: Add-k smoothing or Kneser-Ney\n",
    "   - Current: Simple MLE with backoff\n",
    "   - Improvement: +3-8% accuracy\n",
    "\n",
    "3. **KenLM**: Use optimized library with Modified Kneser-Ney\n",
    "   - Expected: 58-65% accuracy\n",
    "   - Best pure n-gram performance\n",
    "\n",
    "4. **Advanced methods**: Neural models (LSTM, BiLSTM) or model ensembles\n",
    "   - See notebooks 7-9 for neural approaches\n",
    "   - See notebook 6 for ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
