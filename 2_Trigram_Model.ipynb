{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 2) Trigram Language Model (Baseline #1)\n",
    "\n",
    "This notebook implements a trigram language model for next-word prediction.\n",
    "\n",
    "**Model Description:**\n",
    "- Predicts next word based on previous 2 words\n",
    "- Uses Maximum Likelihood Estimation (MLE): P(w_i | w_{i-2}, w_{i-1}) = Count(w_{i-2}, w_{i-1}, w_i) / Count(w_{i-2}, w_{i-1})\n",
    "- Filters candidates by first letter constraint\n",
    "- Falls back to bigram → unigram if trigram not seen\n",
    "\n",
    "**Expected Performance:**\n",
    "- 10K data: ~18-20% accuracy\n",
    "- 100K data: ~33-37% accuracy\n",
    "- 1M data: ~50-52% accuracy\n",
    "- Full (3.8M) data: ~52-55% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "## 2.1 Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple, Dict\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## 2.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Total training sentences: 3,803,957\n",
      "\n",
      "Loading development set...\n",
      "Development set size: 94,825 predictions\n",
      "Columns: ['context', 'first letter', 'answer']\n",
      "\n",
      "Sample dev set entries:\n",
      "                                             context first letter   answer\n",
      "0  south korea and the united states on monday wa...            d      day\n",
      "1  after agreeing to drastically cut its car impo...            t      the\n",
      "2  three soldiers were injured in a bombing ambus...            m  morning\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('train.src.tok', 'r', encoding='utf-8') as f:\n",
    "    train_lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"Total training sentences: {len(train_lines):,}\")\n",
    "\n",
    "# Load dev set\n",
    "print(\"\\nLoading development set...\")\n",
    "dev_df = pd.read_csv('dev_set.csv')\n",
    "print(f\"Development set size: {len(dev_df):,} predictions\")\n",
    "print(f\"Columns: {list(dev_df.columns)}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample dev set entries:\")\n",
    "print(dev_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_sampling_header",
   "metadata": {},
   "source": [
    "## 2.3 Data Sampling\n",
    "\n",
    "We'll use simple sequential sampling (first N sentences) as decided in EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "data_sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using full dataset: 3,803,957 sentences\n",
      "\n",
      "First 3 training sentences:\n",
      "1. australia ' s current account deficit shrunk by a record 1 . 11 billion dollars - lrb - 1 . 11 billion us - rrb - in the june quarter due to soaring commodity prices , figures released monday showed .\n",
      "2. at least two people were killed in a suspected bomb attack on a passenger bus in the strife - torn southern philippines on monday , the military said .\n",
      "3. australian shares closed down 1 . 1 percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n"
     ]
    }
   ],
   "source": [
    "# Data sizes for experiments\n",
    "DATA_SIZES = {\n",
    "    'debug': 10_000,\n",
    "    'dev': 100_000,\n",
    "    'large': 1_000_000,\n",
    "    'full': 3_803_957\n",
    "}\n",
    "\n",
    "def sample_data(train_lines: List[str], size_key: str = 'debug') -> List[str]:\n",
    "    \"\"\"\n",
    "    Sample training data sequentially (simple, no shuffling).\n",
    "    \n",
    "    Args:\n",
    "        train_lines: Full training corpus\n",
    "        size_key: One of 'debug', 'dev', 'large', 'full'\n",
    "    \n",
    "    Returns:\n",
    "        First N sentences from corpus\n",
    "    \"\"\"\n",
    "    size = DATA_SIZES[size_key]\n",
    "    if size >= len(train_lines):\n",
    "        return train_lines\n",
    "    return train_lines[:size]\n",
    "\n",
    "# Start with debug size (10K) for fast testing\n",
    "# Change to 'dev', 'large', or 'full' later\n",
    "# CURRENT_SIZE = 'debug'\n",
    "# CURRENT_SIZE = 'dev'\n",
    "# CURRENT_SIZE = 'large'\n",
    "CURRENT_SIZE = 'full'\n",
    "\n",
    "train_data = sample_data(train_lines, CURRENT_SIZE)\n",
    "print(f\"Using {CURRENT_SIZE} dataset: {len(train_data):,} sentences\")\n",
    "print(f\"\\nFirst 3 training sentences:\")\n",
    "for i, sent in enumerate(train_data[:3]):\n",
    "    print(f\"{i+1}. {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trigram_class_header",
   "metadata": {},
   "source": [
    "## 2.4 Trigram Model Implementation\n",
    "\n",
    "### Key Design Decisions:\n",
    "\n",
    "1. **Sentence boundaries**: Add `<s>` at start and `</s>` at end\n",
    "   - This ensures we don't use context from previous sentence\n",
    "   - Follows standard n-gram practice\n",
    "\n",
    "2. **Backoff strategy**: Trigram → Bigram → Unigram\n",
    "   - If trigram (w1, w2, ?) not seen, fall back to bigram (w2, ?)\n",
    "   - If bigram not seen, fall back to unigram (?)\n",
    "   - If unigram not seen, use most common word with that first letter\n",
    "\n",
    "3. **First letter filtering**:\n",
    "   - Build vocabulary index by first character\n",
    "   - Only consider words starting with given first letter\n",
    "   - Handles special characters (`,`, `'`, `1`, etc.)\n",
    "\n",
    "4. **Data structures**:\n",
    "   - `trigram_counts`: Dict[(w1, w2, w3)] → count\n",
    "   - `bigram_counts`: Dict[(w1, w2)] → count\n",
    "   - `unigram_counts`: Dict[w] → count\n",
    "   - `vocab_by_first_char`: Dict[char] → List[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "trigram_class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrigramModel class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class TrigramModel:\n",
    "    \"\"\"\n",
    "    Trigram language model with backoff strategy.\n",
    "    \n",
    "    Predicts P(w_i | w_{i-2}, w_{i-1}) using Maximum Likelihood Estimation.\n",
    "    Falls back to bigram/unigram if trigram not seen.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # N-gram counts\n",
    "        self.trigram_counts = defaultdict(int)   # (w1, w2, w3) -> count\n",
    "        self.bigram_counts = defaultdict(int)    # (w1, w2) -> count\n",
    "        self.unigram_counts = defaultdict(int)   # w -> count\n",
    "        \n",
    "        # Context counts (for probability calculation)\n",
    "        self.bigram_context_counts = defaultdict(int)  # (w1, w2) -> count\n",
    "        self.unigram_context_counts = defaultdict(int)  # w1 -> count\n",
    "        \n",
    "        # Vocabulary indexed by first character\n",
    "        self.vocab_by_first_char = defaultdict(set)  # char -> {words}\n",
    "        \n",
    "        # Statistics\n",
    "        self.total_trigrams = 0\n",
    "        self.total_bigrams = 0\n",
    "        self.total_unigrams = 0\n",
    "        \n",
    "    def train(self, sentences: List[str]):\n",
    "        \"\"\"\n",
    "        Train the trigram model on a list of sentences.\n",
    "        \n",
    "        Args:\n",
    "            sentences: List of tokenized sentences (strings)\n",
    "        \"\"\"\n",
    "        print(f\"Training trigram model on {len(sentences):,} sentences...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for sentence in tqdm(sentences, desc=\"Processing sentences\"):\n",
    "            # Tokenize sentence\n",
    "            tokens = sentence.split()\n",
    "            \n",
    "            # Add sentence boundaries\n",
    "            # We use TWO <s> tokens at start for trigram context\n",
    "            tokens = ['<s>', '<s>'] + tokens + ['</s>']\n",
    "            \n",
    "            # Extract n-grams and count\n",
    "            for i in range(len(tokens)):\n",
    "                # Unigram\n",
    "                if i >= 2:  # Skip the <s> tokens\n",
    "                    word = tokens[i]\n",
    "                    self.unigram_counts[word] += 1\n",
    "                    self.total_unigrams += 1\n",
    "                    \n",
    "                    # Add to vocabulary index\n",
    "                    if word not in ['<s>', '</s>']:\n",
    "                        first_char = word[0]\n",
    "                        self.vocab_by_first_char[first_char].add(word)\n",
    "                \n",
    "                # Bigram\n",
    "                if i >= 1:\n",
    "                    bigram = (tokens[i-1], tokens[i])\n",
    "                    self.bigram_counts[bigram] += 1\n",
    "                    self.total_bigrams += 1\n",
    "                    \n",
    "                    # Count context (for probability: count(w1, w2) / count(w1))\n",
    "                    if i >= 2:\n",
    "                        self.unigram_context_counts[tokens[i-1]] += 1\n",
    "                \n",
    "                # Trigram\n",
    "                if i >= 2:\n",
    "                    trigram = (tokens[i-2], tokens[i-1], tokens[i])\n",
    "                    self.trigram_counts[trigram] += 1\n",
    "                    self.total_trigrams += 1\n",
    "                    \n",
    "                    # Count context (for probability: count(w1, w2, w3) / count(w1, w2))\n",
    "                    context = (tokens[i-2], tokens[i-1])\n",
    "                    self.bigram_context_counts[context] += 1\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nTraining complete in {elapsed:.2f} seconds\")\n",
    "        print(f\"Total trigrams: {self.total_trigrams:,}\")\n",
    "        print(f\"Total bigrams: {self.total_bigrams:,}\")\n",
    "        print(f\"Total unigrams: {self.total_unigrams:,}\")\n",
    "        print(f\"Unique trigrams: {len(self.trigram_counts):,}\")\n",
    "        print(f\"Unique bigrams: {len(self.bigram_counts):,}\")\n",
    "        print(f\"Unique unigrams: {len(self.unigram_counts):,}\")\n",
    "        print(f\"Vocabulary size: {sum(len(words) for words in self.vocab_by_first_char.values()):,}\")\n",
    "    \n",
    "    def get_trigram_prob(self, w1: str, w2: str, w3: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w3 | w1, w2) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if trigram never seen)\n",
    "        \"\"\"\n",
    "        trigram = (w1, w2, w3)\n",
    "        context = (w1, w2)\n",
    "        \n",
    "        trigram_count = self.trigram_counts.get(trigram, 0)\n",
    "        context_count = self.bigram_context_counts.get(context, 0)\n",
    "        \n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return trigram_count / context_count\n",
    "    \n",
    "    def get_bigram_prob(self, w1: str, w2: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w2 | w1) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if bigram never seen)\n",
    "        \"\"\"\n",
    "        bigram = (w1, w2)\n",
    "        \n",
    "        bigram_count = self.bigram_counts.get(bigram, 0)\n",
    "        context_count = self.unigram_context_counts.get(w1, 0)\n",
    "        \n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return bigram_count / context_count\n",
    "    \n",
    "    def get_unigram_prob(self, w: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate P(w) using MLE.\n",
    "        \n",
    "        Returns:\n",
    "            Probability (0 if word never seen)\n",
    "        \"\"\"\n",
    "        if self.total_unigrams == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return self.unigram_counts.get(w, 0) / self.total_unigrams\n",
    "    \n",
    "    def predict(self, context: str, first_letter: str) -> str:\n",
    "        \"\"\"\n",
    "        Predict next word given context and first letter constraint.\n",
    "        \n",
    "        Args:\n",
    "            context: Previous words as string (e.g., \"the cat sat on the\")\n",
    "            first_letter: Required first character of prediction\n",
    "        \n",
    "        Returns:\n",
    "            Predicted word (most likely word starting with first_letter)\n",
    "        \"\"\"\n",
    "        # Tokenize context and get last 2 words\n",
    "        context_tokens = context.split()\n",
    "        \n",
    "        # Handle short contexts\n",
    "        if len(context_tokens) == 0:\n",
    "            w1, w2 = '<s>', '<s>'\n",
    "        elif len(context_tokens) == 1:\n",
    "            w1, w2 = '<s>', context_tokens[0]\n",
    "        else:\n",
    "            w1, w2 = context_tokens[-2], context_tokens[-1]\n",
    "        \n",
    "        # Get candidate words (all words starting with first_letter)\n",
    "        candidates = self.vocab_by_first_char.get(first_letter, set())\n",
    "        \n",
    "        if not candidates:\n",
    "            # No words in vocabulary start with this letter\n",
    "            # This shouldn't happen with our data, but handle gracefully\n",
    "            return first_letter  # Return just the letter\n",
    "        \n",
    "        # Score candidates using backoff strategy\n",
    "        best_word = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for word in candidates:\n",
    "            # Try trigram first\n",
    "            score = self.get_trigram_prob(w1, w2, word)\n",
    "            \n",
    "            # If trigram not seen, back off to bigram\n",
    "            if score == 0:\n",
    "                score = self.get_bigram_prob(w2, word)\n",
    "            \n",
    "            # If bigram not seen, back off to unigram\n",
    "            if score == 0:\n",
    "                score = self.get_unigram_prob(word)\n",
    "            \n",
    "            # Update best\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_word = word\n",
    "        \n",
    "        # If still no match, return most common word with this first letter\n",
    "        if best_word is None:\n",
    "            # Get most common word by unigram count\n",
    "            candidates_list = list(candidates)\n",
    "            best_word = max(candidates_list, \n",
    "                          key=lambda w: self.unigram_counts.get(w, 0))\n",
    "        \n",
    "        return best_word\n",
    "    \n",
    "    def evaluate(self, dev_df: pd.DataFrame, max_examples: int = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate model on development set.\n",
    "        \n",
    "        Args:\n",
    "            dev_df: DataFrame with columns ['context', 'first letter', 'answer']\n",
    "            max_examples: Optional limit on number of examples to evaluate\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with accuracy and other metrics\n",
    "        \"\"\"\n",
    "        print(f\"\\nEvaluating on development set...\")\n",
    "        \n",
    "        if max_examples:\n",
    "            dev_df = dev_df.head(max_examples)\n",
    "        \n",
    "        correct = 0\n",
    "        total = len(dev_df)\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for idx, row in tqdm(dev_df.iterrows(), total=total, desc=\"Predicting\"):\n",
    "            context = row['context']\n",
    "            first_letter = row['first letter']\n",
    "            answer = row['answer']\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.predict(context, first_letter)\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "            # Check correctness\n",
    "            if prediction == answer:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Total examples: {total:,}\")\n",
    "        print(f\"  Correct: {correct:,}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'correct': correct,\n",
    "            'total': total,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "\n",
    "print(\"TrigramModel class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_header",
   "metadata": {},
   "source": [
    "## 2.5 Train Model\n",
    "\n",
    "Let's train on the debug dataset (10K sentences) first to test everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "train_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training trigram model on 3,803,957 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 3803957/3803957 [05:56<00:00, 10658.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 356.90 seconds\n",
      "Total trigrams: 132,086,229\n",
      "Total bigrams: 135,890,186\n",
      "Total unigrams: 132,086,229\n",
      "Unique trigrams: 27,500,824\n",
      "Unique bigrams: 6,376,191\n",
      "Unique unigrams: 99,022\n",
      "Vocabulary size: 99,021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = TrigramModel()\n",
    "\n",
    "# Train\n",
    "model.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_predictions_header",
   "metadata": {},
   "source": [
    "## 2.6 Test Predictions\n",
    "\n",
    "Let's test on a few manual examples before evaluating on dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "test_predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predictions:\n",
      "\n",
      "Context: 'the cat sat on the'\n",
      "First letter: 'm'\n",
      "Prediction: middle\n",
      "\n",
      "Context: 'president of the united'\n",
      "First letter: 's'\n",
      "Prediction: states\n",
      "\n",
      "Context: 'new york'\n",
      "First letter: 'c'\n",
      "Prediction: city\n",
      "\n",
      "Context: 'in the'\n",
      "First letter: 'm'\n",
      "Prediction: middle\n",
      "\n",
      "Context: 'on'\n",
      "First letter: 'm'\n",
      "Prediction: monday\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test examples\n",
    "test_cases = [\n",
    "    (\"the cat sat on the\", \"m\"),  # mat?\n",
    "    (\"president of the united\", \"s\"),  # states?\n",
    "    (\"new york\", \"c\"),  # city?\n",
    "    (\"in the\", \"m\"),  # morning? middle?\n",
    "    (\"on\", \"m\"),  # monday?\n",
    "]\n",
    "\n",
    "print(\"Testing predictions:\\n\")\n",
    "for context, first_letter in test_cases:\n",
    "    prediction = model.predict(context, first_letter)\n",
    "    print(f\"Context: '{context}'\")\n",
    "    print(f\"First letter: '{first_letter}'\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate_header",
   "metadata": {},
   "source": [
    "## 2.7 Evaluate on Dev Set\n",
    "\n",
    "Now let's evaluate on the full development set (all 94,825 examples).\n",
    "\n",
    "**Note:** Evaluation takes ~30-60 seconds for 10K training data, longer for larger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "evaluate_dev",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on development set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 94825/94825 [13:56<00:00, 113.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Total examples: 94,825\n",
      "  Correct: 55,116\n",
      "  Accuracy: 0.5812 (58.12%)\n",
      "\n",
      "Expected accuracy for full dataset: ~18-20%\n",
      "Actual accuracy: 58.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on full dev set\n",
    "# This will take ~30-60 seconds for 10K training data\n",
    "# Change max_examples=1000 for quick testing\n",
    "results = model.evaluate(dev_df, max_examples=None)\n",
    "\n",
    "print(f\"\\nExpected accuracy for {CURRENT_SIZE} dataset: ~18-20%\")\n",
    "print(f\"Actual accuracy: {results['accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis_header",
   "metadata": {},
   "source": [
    "## 2.8 Error Analysis\n",
    "\n",
    "Let's look at some examples where the model got it right vs wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "error_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CORRECT PREDICTIONS (Sample of 5)\n",
      "================================================================================\n",
      "\n",
      "Context: after agreeing to drastically cut its car import duties , taiwan on thursday won european union support for its bid to enter\n",
      "First letter: 't'\n",
      "Prediction: the\n",
      "Answer: the\n",
      "✓ CORRECT\n",
      "\n",
      "Context: three soldiers were injured in a bombing ambush launched by suspect thai southern insurgents on wednesday\n",
      "First letter: 'm'\n",
      "Prediction: morning\n",
      "Answer: morning\n",
      "✓ CORRECT\n",
      "\n",
      "Context: the movement for democracy in liberia - lrb - model - rrb - , the second largest rebel group in war - ravaged west african country has made a firm commitment to continue with the peace talks in ghana , according\n",
      "First letter: 't'\n",
      "Prediction: to\n",
      "Answer: to\n",
      "✓ CORRECT\n",
      "\n",
      "Context: an indian court that heard a stunning confession from the lone surviving gunman in the mumbai attacks put a gag order on his latest testimony - - a message to his handlers in pakistan and\n",
      "First letter: 'a'\n",
      "Prediction: a\n",
      "Answer: a\n",
      "✓ CORRECT\n",
      "\n",
      "Context: authorities in belarus detained two prominent russian lawmakers at the border on wednesday and put them on a plane back to\n",
      "First letter: 'm'\n",
      "Prediction: moscow\n",
      "Answer: moscow\n",
      "✓ CORRECT\n",
      "\n",
      "================================================================================\n",
      "INCORRECT PREDICTIONS (Sample of 5)\n",
      "================================================================================\n",
      "\n",
      "Context: south korea and the united states on monday warned north korea to avoid provoking trouble as pyongyang ' s most senior defector spent his sixth\n",
      "First letter: 'd'\n",
      "Prediction: dollars\n",
      "Answer: day\n",
      "✗ INCORRECT\n",
      "\n",
      "Context: an aviation official says a yemeni investigation team has found that a yemeni airplane that crashed off the comoros islands last month\n",
      "First letter: 'w'\n",
      "Prediction: were\n",
      "Answer: was\n",
      "✗ INCORRECT\n",
      "\n",
      "Context: concerned that several environmental laws are interfering with the military ' s ability to train soldiers and develop weapons , the pentagon is seeking a congressional exemption from an array of measures\n",
      "First letter: 't'\n",
      "Prediction: to\n",
      "Answer: that\n",
      "✗ INCORRECT\n",
      "\n",
      "Context: bahrainis went to the polls thursday for a second round of landmark legislative elections , and for the first time in a gulf arab nation , two\n",
      "First letter: 'w'\n",
      "Prediction: weeks\n",
      "Answer: women\n",
      "✗ INCORRECT\n",
      "\n",
      "Context: a spanish trawler was under escort to the western french port of la rochelle on sunday after fisheries inspectors found three\n",
      "First letter: 't'\n",
      "Prediction: the\n",
      "Answer: tonnes\n",
      "✗ INCORRECT\n"
     ]
    }
   ],
   "source": [
    "# Add predictions to dev_df\n",
    "# Note: This uses all predictions from the full dev set evaluation above\n",
    "dev_sample = dev_df.copy()\n",
    "dev_sample['prediction'] = results['predictions']\n",
    "dev_sample['correct'] = dev_sample['prediction'] == dev_sample['answer']\n",
    "\n",
    "# Show correct predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRECT PREDICTIONS (Sample of 5)\")\n",
    "print(\"=\" * 80)\n",
    "correct_samples = dev_sample[dev_sample['correct']].head(5)\n",
    "for idx, row in correct_samples.iterrows():\n",
    "    print(f\"\\nContext: {row['context']}\")\n",
    "    print(f\"First letter: '{row['first letter']}'\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Answer: {row['answer']}\")\n",
    "    print(f\"✓ CORRECT\")\n",
    "\n",
    "# Show incorrect predictions\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INCORRECT PREDICTIONS (Sample of 5)\")\n",
    "print(\"=\" * 80)\n",
    "incorrect_samples = dev_sample[~dev_sample['correct']].head(5)\n",
    "for idx, row in incorrect_samples.iterrows():\n",
    "    print(f\"\\nContext: {row['context']}\")\n",
    "    print(f\"First letter: '{row['first letter']}'\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Answer: {row['answer']}\")\n",
    "    print(f\"✗ INCORRECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling_header",
   "metadata": {},
   "source": [
    "## 2.9 Scaling Experiments\n",
    "\n",
    "Now let's see how accuracy changes with more training data.\n",
    "\n",
    "**Note:** This will take progressively longer:\n",
    "- 10K: ~10 seconds\n",
    "- 100K: ~1-2 minutes\n",
    "- 1M: ~10-15 minutes\n",
    "- Full (3.8M): ~40-60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "scaling_experiments",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING ON DEBUG DATASET (10,000 sentences)\n",
      "================================================================================\n",
      "Training trigram model on 10,000 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 10000/10000 [00:00<00:00, 25352.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 0.40 seconds\n",
      "Total trigrams: 337,976\n",
      "Total bigrams: 347,976\n",
      "Total unigrams: 337,976\n",
      "Unique trigrams: 185,369\n",
      "Unique bigrams: 102,716\n",
      "Unique unigrams: 14,885\n",
      "Vocabulary size: 14,884\n",
      "\n",
      "Evaluating on development set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 94825/94825 [00:28<00:00, 3367.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Total examples: 94,825\n",
      "  Correct: 41,172\n",
      "  Accuracy: 0.4342 (43.42%)\n",
      "\n",
      "================================================================================\n",
      "TRAINING ON DEV DATASET (100,000 sentences)\n",
      "================================================================================\n",
      "Training trigram model on 100,000 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 100000/100000 [00:04<00:00, 21178.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 4.72 seconds\n",
      "Total trigrams: 3,435,020\n",
      "Total bigrams: 3,535,020\n",
      "Total unigrams: 3,435,020\n",
      "Unique trigrams: 1,454,743\n",
      "Unique bigrams: 576,344\n",
      "Unique unigrams: 42,351\n",
      "Vocabulary size: 42,350\n",
      "\n",
      "Evaluating on development set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 94825/94825 [02:02<00:00, 774.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Total examples: 94,825\n",
      "  Correct: 47,310\n",
      "  Accuracy: 0.4989 (49.89%)\n",
      "\n",
      "================================================================================\n",
      "TRAINING ON LARGE DATASET (1,000,000 sentences)\n",
      "================================================================================\n",
      "Training trigram model on 1,000,000 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 1000000/1000000 [00:56<00:00, 17693.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 56.52 seconds\n",
      "Total trigrams: 34,184,775\n",
      "Total bigrams: 35,184,775\n",
      "Total unigrams: 34,184,775\n",
      "Unique trigrams: 8,776,975\n",
      "Unique bigrams: 2,433,677\n",
      "Unique unigrams: 79,021\n",
      "Vocabulary size: 79,020\n",
      "\n",
      "Evaluating on development set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 94825/94825 [05:14<00:00, 301.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Total examples: 94,825\n",
      "  Correct: 51,285\n",
      "  Accuracy: 0.5408 (54.08%)\n",
      "\n",
      "================================================================================\n",
      "SCALING RESULTS SUMMARY\n",
      "================================================================================\n",
      "Dataset         # Sentences     Accuracy       \n",
      "---------------------------------------------\n",
      "debug           10,000          43.42         %\n",
      "dev             100,000         49.89         %\n",
      "large           1,000,000       54.08         %\n"
     ]
    }
   ],
   "source": [
    "# Run experiments on different data sizes\n",
    "# Comment out sizes you don't want to run\n",
    "sizes_to_test = [\n",
    "    'debug',   # 10K\n",
    "    'dev',     # 100K\n",
    "    'large',   # 1M\n",
    "    # 'full',    # 3.8M\n",
    "]\n",
    "\n",
    "scaling_results = []\n",
    "\n",
    "for size_key in sizes_to_test:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"TRAINING ON {size_key.upper()} DATASET ({DATA_SIZES[size_key]:,} sentences)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Sample data\n",
    "    data = sample_data(train_lines, size_key)\n",
    "    \n",
    "    # Train model\n",
    "    model = TrigramModel()\n",
    "    model.train(data)\n",
    "    \n",
    "    # Evaluate on full dev set\n",
    "    # This takes ~30-60 seconds per model\n",
    "    results = model.evaluate(dev_df, max_examples=None)\n",
    "    \n",
    "    # Store results\n",
    "    scaling_results.append({\n",
    "        'size': size_key,\n",
    "        'num_sentences': len(data),\n",
    "        'accuracy': results['accuracy']\n",
    "    })\n",
    "\n",
    "# Show summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SCALING RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Dataset':<15} {'# Sentences':<15} {'Accuracy':<15}\")\n",
    "print(\"-\" * 45)\n",
    "for result in scaling_results:\n",
    "    print(f\"{result['size']:<15} {result['num_sentences']:<15,} {result['accuracy']*100:<14.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_model_header",
   "metadata": {},
   "source": [
    "## 2.10 Save Model (Optional)\n",
    "\n",
    "Save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_model",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrigram_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCURRENT_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# To load later:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# with open(model_filename, 'rb') as f:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     loaded_model = pickle.load(f)\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "model_filename = f'trigram_model_{CURRENT_SIZE}.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# To load later:\n",
    "# with open(model_filename, 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efda3dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5382.06 MB\n",
      "⚠️ WARNING: Model is too large to save!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Quick model size check\n",
    "def get_size_mb(obj):\n",
    "    \"\"\"Get approximate size in MB\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        for key, val in obj.__dict__.items():\n",
    "            size += sys.getsizeof(val)\n",
    "            if isinstance(val, dict):\n",
    "                for k, v in val.items():\n",
    "                    size += sys.getsizeof(k) + sys.getsizeof(v)\n",
    "    return size / (1024 * 1024)\n",
    "\n",
    "# Check model size\n",
    "size_mb = get_size_mb(model)\n",
    "print(f\"Model size: {size_mb:.2f} MB\")\n",
    "\n",
    "if size_mb > 500:\n",
    "    print(\"⚠️ WARNING: Model is too large to save!\")\n",
    "else:\n",
    "    print(\"✓ Safe to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps_header",
   "metadata": {},
   "source": [
    "## 2.11 Next Steps\n",
    "\n",
    "**Current Status:**\n",
    "- ✅ Trigram model implemented\n",
    "- ✅ Tested on debug dataset (10K)\n",
    "- ✅ Evaluated on dev set\n",
    "\n",
    "**To improve performance:**\n",
    "\n",
    "1. **More data**: Train on larger datasets (100K, 1M, Full)\n",
    "   - Expected: ~33-37% on 100K, ~50-52% on 1M, ~52-55% on Full\n",
    "\n",
    "2. **Better smoothing**: Add-k smoothing or Kneser-Ney\n",
    "   - Current: Simple MLE with backoff\n",
    "   - Improvement: +3-8% accuracy\n",
    "\n",
    "3. **Higher-order n-grams**: 4-gram or 5-gram\n",
    "   - More context → better predictions\n",
    "   - Expected: +3-5% accuracy\n",
    "\n",
    "4. **KenLM**: Use optimized library with Modified Kneser-Ney\n",
    "   - Expected: 58-65% accuracy\n",
    "\n",
    "**Next notebook:**\n",
    "- `3_4gram_Model.ipynb` - Implement 4-gram baseline\n",
    "- Or jump to `3_KenLM.ipynb` for best n-gram performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
